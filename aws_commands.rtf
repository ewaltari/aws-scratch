AWS commands:

### CREATE INSTANCE
## the specops instance image has aws, git BUT NOT DOCKER

aegea launch waltari-immcantation --ami-tags Name=czbiohub-specops --iam-role S3fromEC2 -t m4.4xlarge
aegea ssh ubuntu@waltari-immcantation

## To stop:
aegea stop waltari-immcantation
## To restart
aegea start waltari-immcantation

## FYI: if after restarting your Mac, YOU MAY NOT BE ABLE TO USE aegea start (name)
  ## if this happens, use ssh: point to .pem file and use ubuntu@latest.address
  ## also note every time you stop and restart, the long address name changes!
ssh -i .ssh/aegea.launch.eric.waltari.waltari-mbp.pem ubuntu@XXX.us-west-2.compute.amazonaws.com
  ## to get full name - go to 
https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:sort=keyName
  ## Then click on immcantation instance tab, ‘connect’, and an instruction box will pop-up with the address to use

————
### INSTALLING & STARTING DOCKER
## install with these commands

## install with these commands (http://ray.readthedocs.io/en/latest/install-on-docker.html)
## The instructions below show in detail how to prepare an Amazon EC2 instance running Ubuntu 16.04 for use with Docker. 
## initialize the package repository and apply system updates:
sudo apt-get update
sudo apt-get -y dist-upgrade
## Install Docker and start the service:
sudo apt-get install -y docker.io
sudo service docker start
## add the ubuntu user to the docker group to allow running Docker commands without sudo:
sudo usermod -a -G docker ubuntu

## Log out and log back in again…
## Confirm that docker is running:
docker images

## NEED TO CHANGE DIRECTORY TO WHERE DOCKER WORKS:
https://github.com/IronicBadger/til/blob/master/docker/change-docker-root.md
## then restart docker

————
### TRANSFER FILES FROM S3
## first need to configure aws:
aws configure
## basic: create directories you need
mkdir mnt/data/presto

## basic: type all aws commands from root directory before running
## transferring base scripts, some initial .yaml files and unzipped fastqs from first MiSeq runs (all in my s3 bucket):
aws s3 cp --recursive s3://eric.waltari-bucket/BX_miseq/presto/ /mnt/data/presto


## example to transfer one MiSeq run to aegea instance
aws s3 cp --recursive s3://czbiohub-seqbot/fastqs/180128_M05295_0078_000000000-BJNBT/rawdata/presto/ /mnt/data/presto
aws s3 cp --recursive s3://czbiohub-seqbot/fastqs/180629_M05295_0128_000000000-BNRF9/rawdata/ /mnt/data/presto

## basic: unzip fastq.gz files before running PRESTO
gunzip *fastq.gz
## basic: make sure to set chmod for scripts
chmod a+x *.sh

————
### DOCKER COMMANDS
docker pull kleinstein/immcantation:1.10.0 
## MARCH 1.7.0, APRIL 1.8.0, LATE APRIL 1.9.0, Late May 1.10.0 (http://immcantation.readthedocs.io/en/latest/docker/news.html)
  ## July 1.10.2
## basic: first go to root directory before running docker

## to get docker shell to see files on Aegea
docker run -it -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.0 bash
## or to get to docker shell to see files locally
docker run -it -v $HOME/testing/2018mar_miseq_full:/data:z kleinstein/immcantation:1.10.0 bash
## use to make sure that all files are where they should be (check /data and /usr/local/share folders are also there)

## also to check Docker runs, and stop if necessary
docker ps                 # get the id of the running container
docker stop <containerid> # kill it (gracefully)

————
## FIRST STEP OF IMMCANTATION: PRESTO
  ## NOTE SETTINGS IN presto-abseq.sh
  ## PRIMER THRESHOLD 0.3
  ## IN PARTICULAR THE # OF MINIMUM BARCODES (LATEST SETTING IS 5)

## in mid-March first full run of BX MiSeq dataset
## in April changed primer names so can combine them (also added a line in presto-abseq.sh commands to do the combine step)
            ## the line I added: ParseHeaders.py copy -s reads.fastq -f PRCONS -k PRIMER --act first
## then in mid-May noticed another primer sequence error, final versions of primers.fasta files are made between 4.27 and 5.23


## DOCKER COMMAND TO RUN PRESTO IN AEGEA
docker run -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.0 /data/presto-abseq.sh -1 /data/Undetermined_S0_L001_R2_001.fastq -2 /data/Undetermined_S0_L001_R1_001.fastq -j /data/primers_R2c.fasta -v data/primers_R1.fasta -r /usr/local/share/igblast/fasta/imgt_human_ig_v.fasta -y /data/apr18_full.yaml -n BXjan5 -o /data/BXjan_filter5 -p 16 | sudo tee run_presto.out

docker run -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.0 /data/presto-abseq.sh -1 /data/BX0525_1mPBMC_noenrich_HL_S3_R2_001.fastq -2 /data/BX0525_1mPBMC_noenrich_HL_S3_R1_001.fastq -j /data/primers_R2hl.fasta -v data/primers_R1hl.fasta -r /usr/local/share/igblast/fasta/imgt_human_ig_v.fasta -y /data/jul18_BX0525_1mnotenriched.yaml -n BX0525_1mnotenriched -o /data/BX0525_1mnotenriched -p 16 | sudo tee run_presto.out

docker run -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.0 /data/presto-abseq.sh -1 /data/BX0525_1mPBMC_HL_S2_R2_001.fastq -2 /data/BX0525_1mPBMC_HL_S2_R1_001.fastq -j /data/primers_R2hl.fasta -v data/primers_R1hl.fasta -r /usr/local/share/igblast/fasta/imgt_human_ig_v.fasta -y /data/jul18_BX0525_1menriched.yaml -n BX0525_1menriched -o /data/BX0525_1menriched -p 16 | sudo tee run_presto.out

docker run -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.0 /data/presto-abseq.sh -1 /data/BX0525_30mPBMC_HL_S1_R2_001.fastq -2 /data/BX0525_30mPBMC_HL_S1_R1_001.fastq -j /data/primers_R2hl.fasta -v data/primers_R1hl.fasta -r /usr/local/share/igblast/fasta/imgt_human_ig_v.fasta -y /data/jul18_BX0525_30m.yaml -n BX0525_30m -o /data/BX0525_30m -p 16 | sudo tee run_presto.out


## when each run is done (preferably before final step of zipping most intermediate files), transfer files back to s3
  ## three fastq outputs, and the .pdf report
  ## examples:
aws s3 cp /mnt/data/presto/BXapr_filter5/BXapr5-final_collapse-unique.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/BXapr5-final_collapse-unique.fastq
aws s3 cp /mnt/data/presto/BXapr_filter5/BXapr5-final_collapse-unique_atleast-5.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/BXapr5-final_collapse-unique_atleast-5.fastq
aws s3 cp /mnt/data/presto/BXapr_filter5/BXapr5-final_total.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/BXapr5-final_total.fastq
aws s3 cp /mnt/data/presto/BXapr_filter5/report/MiSeq_apr_BX_full5_04272018.pdf s3://eric.waltari-bucket/BX_miseq/presto/output/MiSeq_apr_BX_full5_04272018.pdf

  ## also now at end of script isotype information is in 2 separate files:
  ## note that it would be better to concatenate each of the *primers-pass.fastq and *primers-fail.fastq files...
aws s3 cp /mnt/data/presto/BXapr_filter5/BXapr5-final_collapse-unique_primers-pass.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/BXapr5-final_collapse-unique_primers-pass.fastq
aws s3 cp /mnt/data/presto/BXapr_filter5/BXapr5-final_collapse-unique_primers-fail.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/BXapr5-final_collapse-unique_primers-fail.fastq
aws s3 cp /mnt/data/presto/BXapr_filter5/BXapr5-final_collapse-unique_atleast-5_primers-pass.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/BXapr5-final_collapse-unique_atleast-5_primers-pass.fastq
aws s3 cp /mnt/data/presto/BXapr_filter5/BXapr5-final_collapse-unique_atleast-5_primers-fail.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/BXapr5-final_collapse-unique_atleast-5_primers-fail.fastq

## some other transfers
aws s3 cp /mnt/data/presto/BX1milPBMCHL_0627 s3://eric.waltari-bucket/BX_miseq/presto/output/ --recursive --exclude "*" --include "*.fastq"
aws s3 cp /mnt/data/presto/BX1milPBMCHL_0627/report/BX_1millionPBMCHL_BX_1millionPBMC_HL_06042018.pdf s3://eric.waltari-bucket/BX_miseq/presto/output/BX_1millionPBMC_HL_06042018.pdf

aws s3 cp /mnt/data/changeo s3://eric.waltari-bucket/BX_miseq/changeo/output/ --recursive --exclude "*" --include "BXjan5*"
## note when a run is done, the remaining fastqs are not gzipped - also in /logs folder, .tab files are not zipped either
gzip *.fastq
gzip *.tab


### July24 latest run (bead tests)

aws s3 cp --recursive s3://czbiohub-seqbot/fastqs/180720_M05295_0140_000000000-BTMHH/rawdata/ /mnt/data/presto
mkdir d4d5_beadtests
nano jul18_BX0525_30m.yaml

docker run -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.2 /data/presto-abseq.sh -1 /data/d4_1mPBMC_HL_S1_R2_001.fastq -2 /data/d4_1mPBMC_HL_S1_R1_001.fastq -j /data/primers_R2hl.fasta -v data/primers_R1hl.fasta -r /usr/local/share/igblast/fasta/imgt_human_ig_v.fasta -y /data/jul18_d4_1m.yaml -n d4_1m -o /data/d4d5_beadtests -p 16 | sudo tee run_presto.out

docker run -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.2 /data/presto-abseq.sh -1 /data/d4_1mPBMC_beads_HL_S2_R2_001.fastq -2 /data/d4_1mPBMC_beads_HL_S2_R1_001.fastq -j /data/primers_R2hl.fasta -v data/primers_R1hl.fasta -r /usr/local/share/igblast/fasta/imgt_human_ig_v.fasta -y /data/jul18_d4_1m_beads.yaml -n d4_1m_beads -o /data/d4d5_beadtests2 -p 16 | sudo tee run_presto.out
## note 1.10.2 might be leading to pdf generation errors??

docker run -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.0 /data/presto-abseq.sh -1 /data/d5_1mPBMC_beads_HL_S3_R2_001.fastq -2 /data/d5_1mPBMC_beads_HL_S3_R1_001.fastq -j /data/primers_R2hl.fasta -v data/primers_R1hl.fasta -r /usr/local/share/igblast/fasta/imgt_human_ig_v.fasta -y /data/jul18_d5_1m_beads.yaml -n d5_1m_beads -o /data/d4d5_beadtests3 -p 16 | sudo tee run_presto.out

aws s3 cp /mnt/data/presto/d4d5_beadtests/d4_1m-final_collapse-unique_primers-pass.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d4_1m-final_collapse-unique_primers-pass.fastq
aws s3 cp /mnt/data/presto/d4d5_beadtests/d4_1m-final_collapse-unique_primers-fail.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d4_1m-final_collapse-unique_primers-fail.fastq
aws s3 cp /mnt/data/presto/d4d5_beadtests/d4_1m-final_collapse-unique_atleast-2_primers-pass.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d4_1m-final_collapse-unique_atleast-2_primers-pass.fastq
aws s3 cp /mnt/data/presto/d4d5_beadtests/d4_1m-final_collapse-unique_atleast-2_primers-fail.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d4_1m-final_collapse-unique_atleast-2_primers-fail.fastq

aws s3 cp /mnt/data/presto/d4d5_beadtests2/d4_1m_beads-final_collapse-unique_primers-pass.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d4_1m_beads-final_collapse-unique_primers-pass.fastq
aws s3 cp /mnt/data/presto/d4d5_beadtests2/d4_1m_beads-final_collapse-unique_primers-fail.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d4_1m_beads-final_collapse-unique_primers-fail.fastq
aws s3 cp /mnt/data/presto/d4d5_beadtests2/d4_1m_beads-final_collapse-unique_atleast-2_primers-pass.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d4_1m_beads-final_collapse-unique_atleast-2_primers-pass.fastq
aws s3 cp /mnt/data/presto/d4d5_beadtests2/d4_1m_beads-final_collapse-unique_atleast-2_primers-fail.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d4_1m_beads-final_collapse-unique_atleast-2_primers-fail.fastq

aws s3 cp /mnt/data/presto/d4d5_beadtests3/d5_1m_beads-final_collapse-unique_primers-pass.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d5_1m_beads-final_collapse-unique_primers-pass.fastq
aws s3 cp /mnt/data/presto/d4d5_beadtests3/d5_1m_beads-final_collapse-unique_primers-fail.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d5_1m_beads-final_collapse-unique_primers-fail.fastq
aws s3 cp /mnt/data/presto/d4d5_beadtests3/d5_1m_beads-final_collapse-unique_atleast-2_primers-pass.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d5_1m_beads-final_collapse-unique_atleast-2_primers-pass.fastq
aws s3 cp /mnt/data/presto/d4d5_beadtests3/d5_1m_beads-final_collapse-unique_atleast-2_primers-fail.fastq s3://eric.waltari-bucket/BX_miseq/presto/output/d5_1m_beads-final_collapse-unique_atleast-2_primers-fail.fastq

aws s3 cp /mnt/data/presto/d4d5_beadtests1/report/d4d5_beadtests_d4_07242018.pdf s3://eric.waltari-bucket/BX_miseq/presto/output/dd4d5_beadtests_d4_07242018.pdf
aws s3 cp /mnt/data/presto/d4d5_beadtests2b/report/d4d5_beadtests_d4_0724b2018.pdf s3://eric.waltari-bucket/BX_miseq/presto/output/dd4d5_beadtests_d4_0724b2018.pdf
aws s3 cp /mnt/data/presto/d4d5_beadtests3/report/d4d5_beadtests_d5_07252018.pdf s3://eric.waltari-bucket/BX_miseq/presto/output/dd4d5_beadtests_d5_07252018.pdf


aws s3 cp --recursive s3://czbiohub-seqbot/fastqs/180726_M05295_0144_000000000-BTPG3/rawdata/ /mnt/data/presto
mkdir BX_beadtests1
nano jul18_d5_1m_beads.yaml

docker run -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.0 /data/presto-abseq.sh -1 /data/BX_3mPBMC_HL_S2_R2_001.fastq -2 /data/BX_3mPBMC_HL_S2_R1_001.fastq -j /data/primers_R2hl.fasta -v data/primers_R1hl.fasta -r /usr/local/share/igblast/fasta/imgt_human_ig_v.fasta -y /data/jul18_BX_3m.yaml -n BX_3m -o /data/BX_beadtests1 -p 16 | sudo tee run_presto.out

docker run -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.0 /data/presto-abseq.sh -1 /data/BX_3mPBMC_beads_HL_S3_R2_001.fastq -2 /data/BX_3mPBMC_beads_HL_S3_R1_001.fastq -j /data/primers_R2hl.fasta -v data/primers_R1hl.fasta -r /usr/local/share/igblast/fasta/imgt_human_ig_v.fasta -y /data/jul18_BX_3m_beads.yaml -n BX_3m_beads -o /data/BX_beadtests3 -p 16 | sudo tee run_presto.out

docker run -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.0 /data/presto-abseq.sh -1 /data/d5_1mPBMC_HL_S1_R2_001.fastq -2 /data/d5_1mPBMC_HL_S1_R1_001.fastq -j /data/primers_R2hl.fasta -v data/primers_R1hl.fasta -r /usr/local/share/igblast/fasta/imgt_human_ig_v.fasta -y /data/jul18_d5_1m.yaml -n d5_1m -o /data/BX_beadtests2 -p 16 | sudo tee run_presto.out


aws s3 cp /mnt/data/presto/BX_beadtests1 s3://eric.waltari-bucket/BX_miseq/presto/output/ --recursive --exclude "*" --include "*.fastq"
aws s3 cp /mnt/data/presto/BX_beadtests1/report/BX_beadtests_BX_0525_07302018.pdf s3://eric.waltari-bucket/BX_miseq/presto/output/BX_beadtests_BX_0525_07302018.pdf

————
## SECOND STEPS OF IMMCANTATION: CHANGEO
## STEP 2A: IGBLAST
  ## this script includes creating germlines and parsing only functional (example scripts break this into 3 parts)

## running locally:
  ## first put BX-final_collapse-unique_atleast-5.fastq into your folder
  ## first run bash in container to make sure  /usr/local/share/germlines/imgt/human/vdj has IMGT-gapped reference germlines!!
  ## 750k reads takes 3.5 hours
docker run -v $HOME/immcantation_pipeline/BX_min5/changeo:/data:z kleinstein/immcantation:1.10.0 /data/changeoV3.7_IgBLASTV1.7.sh -s /data/BXapr5-final_collapse-unique_atleast-5.fastq -n BXapr -o /data -p 4 | tee run_igblast.out

docker run -v $HOME/immcantation_pipeline/BX_min5/changeo:/data:z kleinstein/immcantation:1.10.0 /data/changeoV3.7_IgBLASTV1.7.sh -s /data/BXjan5-final_collapse-unique_atleast-2_withtargets.fasta -n BXjan2_withss -o /data -p 4 | tee run_igblast.out

## on aegea (first commands to transfer files)
aws s3 cp s3://eric.waltari-bucket/BX_miseq/changeo/ChangeoV3.7_Clone.sh /mnt/data/changeo/ChangeoV3.7_Clone.sh
aws s3 cp s3://eric.waltari-bucket/BX_miseq/changeo/changeoV3.7_IgBLASTV1.7.sh /mnt/data/changeo/changeoV3.7_IgBLASTV1.7.sh
aws s3 cp s3://eric.waltari-bucket/BX_miseq/changeo/output/BXjan2_withss_parse-select.tab /mnt/data/changeo/BXjan2_withss_parse-select.tab

aws s3 cp s3://eric.waltari-bucket/BX_miseq/changeo/output/BXjan5-final_collapse-unique_atleast-5_withtargets.fasta /mnt/data/changeo/BXjan5-final_collapse-unique_atleast-5_withtargets.fasta
aws s3 cp s3://eric.waltari-bucket/BX_miseq/changeo/output/BXjan5-final_collapse-unique_atleast-5_withtargets2.fasta /mnt/data/changeo/BXjan5-final_collapse-unique_atleast-5_withtargets2.fasta

aws s3 cp s3://eric.waltari-bucket/BX_miseq/changeo/output/BXjan5-final_collapse-unique_nearmatches_min390bp_withtargets.fasta /mnt/data/changeo/BXjan5-final_collapse-unique_nearmatches_min390bp_withtargets.fasta

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 /data/changeoV3.7_IgBLASTV1.7.sh -s /data/BXjan5-final_collapse-unique_atleast-5_withtargets.fasta -n BXjan5_withss -o /data -p 16 | sudo tee run_igblast.out

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 /data/changeoV3.7_IgBLASTV1.7.sh -s /data/BXjan5-final_collapse-unique_atleast-5_withtargets2.fasta -n BXjan5_with93ss -o /data -p 16 | sudo tee run_igblast.out

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 /data/changeoV3.7_IgBLASTV1.7.sh -s /data/BXjan5-final_collapse-unique_nearmatches_min390bp_withtargets.fasta -n BXjan5_matcheswithss -o /data -p 16 | sudo tee run_igblast.out

aws s3 cp s3://eric.waltari-bucket/BX_miseq/changeo/output/BXjan5-final_collapse-unique_nearmatches_min390bp_withtargets_fr4trimmed.fasta /mnt/data/changeo/BXjan5-final_collapse-unique_nearmatches_min390bp_withtargets_fr4trimmed.fasta

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 /data/changeoV3.7_IgBLASTV1.7.sh -s /data/BXjan5-final_collapse-unique_nearmatches_min390bp_withtargets_fr4trimmed.fasta -n BXjan5_fr4trimmedmatcheswithss -o /data -p 16 | sudo tee run_igblast.out

## STEP 2B: INFERENCE OF V SEGMENT GENOTYPES (TIGGER)
     ## FULL DATASET RETURNED ERRORS - NOW USING LOCAL R SCRIPT
TiggerV2.10_Genotype.R

## STEP 2C: CLONAL ASSIGNMENT THRESHOLDING
    ## FULL DATASET RETURNED ERRORS - NOW USING LOCAL R SCRIPT
    ## R script of full dataset = 1 hour for db step, ~2 more hours for threshold step
ShazamV1.10Distance.R

# should try running in docker: 
## option A) docker bash, then type: R > R.script --no-save
## option B) 
# Arguments
DATA_DIR=~/project
DB=/data/changeo/sample/sample_genotyped.tab
SAMPLE_NAME=sample
OUT_DIR=/data/changeo/sample
NPROC=4

# Run pipeline in docker image
docker run -v $DATA_DIR:/data:z kleinstein/immcantation:1.10.0 \
    shazam-threshold -d $DB -n $SAMPLE_NAME -o $OUT_DIR -p $NPROC

# Arguments:
#   -d  Change-O formatted TSV (TAB) file.
#   -m  Method.
#       Defaults to density.
#   -l  Model when "-m gmm" is specified.
#       Defaults to "gamma-gamma".
#   -n  Sample name or run identifier which will be used as the output file prefix.
#       Defaults to a truncated version of the input filename.
#   -o  Output directory.
#       Defaults to current directory.
#   -p  Number of subprocesses for multiprocessing tools.
#       Defaults to the available processing units.
#   -h  Display help.

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 shazam-threshold -d /data/BXjan5_withss_parse-select.tab -n BXjan5_withss -o /data -p 16 | sudo tee run_threshold.out

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 shazam-threshold -d /data/BXjan5_with93ss_parse-select.tab -n BXjan5_with93ss -o /data -p 16 | sudo tee run_threshold.out


### STEP2D: CLONAL ASSIGNMENT
  # FIRST GET THRESHOLD (then add to -x below) FROM STEP 2C
## locally
docker run -v $HOME/immcantation_pipeline/BX_min5/changeo:/data:z kleinstein/immcantation:1.10.0 /data/ChangeoV3.7_Clone.sh -d /data/BX_genotyped5t.tab -x 0.0692 -n BX -o /data -p 4 | tee run_clone.out

docker run -v $HOME/immcantation_pipeline/BX_min5/changeo:/data:z kleinstein/immcantation:1.10.0 /data/ChangeoV3.7_Clone.sh -d /data/BX1milPBMCHL_parse-select.tab -x 0.0724 -n BX -o /data -p 4 | tee run_clone.out

docker run -v $HOME/immcantation_pipeline/BX_min5/changeo:/data:z kleinstein/immcantation:1.10.0 /data/ChangeoV3.7_Clone.sh -d /data/BBXjan2_withss_parse-select.tab -x 0.0347 -n BXjan2_withss -o /data -p 4 | tee run_clone.out

## on aegea
aws s3 cp /mnt/data/changeo/BXjan2_withss_clone-pass.tab s3://eric.waltari-bucket/BX_miseq/changeo/output/BXjan2_withss_clone-pass.tab 

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 /data/ChangeoV3.7_Clone.sh -d /data/BXjan2_withss_parse-select.tab -x 0.0347 -n BXjan2_withss -o /data -p 16 | sudo tee run_clone.out

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 /data/ChangeoV3.7_Clone.sh -d /data/BXjan5_withss_parse-select.tab -x 0.0347 -n BXjan5_withss -o /data -p 16 | sudo tee run_clone.out

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 /data/ChangeoV3.7_Clone.sh -d /data/BXjan5_with93ss_parse-select.tab -x 0.0347 -n BXjan5_with93ss -o /data -p 16 | sudo tee run_clone.out

aws s3 cp /mnt/data/changeo/BXjan5_with93ss_clone-pass.tab s3://eric.waltari-bucket/BX_miseq/changeo/output/BXjan5_with93ss_clone-pass.tab

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 /data/ChangeoV3.7_Clone.sh -d /data/BXjan5_matcheswithss_parse-select.tab -x 0.0347 -n BXjan5_matcheswithss -o /data -p 16 | sudo tee run_clone.out

aws s3 cp /mnt/data/changeo/BXjan5_matcheswithss_clone-pass.tab s3://eric.waltari-bucket/BX_miseq/changeo/output/BXjan5_matcheswithss_clone-pass.tab 

docker run -v /mnt/data/changeo:/data:z kleinstein/immcantation:1.10.0 /data/ChangeoV3.7_Clone.sh -d /data/BXjan5_fr4trimmedmatcheswithss_parse-select.tab -x 0.0347 -n BXjan5_fr4trimmedmatcheswithss -o /data -p 16 | sudo tee run_clone.out

aws s3 cp /mnt/data/changeo/BXjan5_fr4trimmedmatcheswithss_clone-pass.tab s3://eric.waltari-bucket/BX_miseq/changeo/output/BXjan5_fr4trimmedmatcheswithss_clone-pass.tab 
————
## FOR MAKING NETWORKS (IN CHANGEO) THAT INCLUDE SEQUENCES FOUND VIA SORTING, MAKE FASTA FILES OF SUCH SEQUENCES THEN RUN:
docker run -v $HOME/testing/2018mar_miseq_full:/data:z kleinstein/immcantation:1.10.0 /data/changeoV3.7_IgBLASTV1.7.sh -s /data/moreINFandAD2.fasta -n moreInfAandAD2 -o /data -p 4 | tee run_igblast.out
docker run -v $HOME/testing/2018mar_miseq_full:/data:z kleinstein/immcantation:1.10.0 shazam-threshold -d /data/moreInfAandAD2_parse-select.tab -n moreInfAandAD2 -o /data -p 4 | tee run_threshold.out
docker run -v $HOME/testing/2018mar_miseq_full:/data:z kleinstein/immcantation:1.10.0 /data/ChangeoV3.7_Clone.sh -d /data/moreInfAandAD2_parse-select.tab -x 0.0396 -n moreInfAandAD2 -o /data -p 4 | tee run_clone.out


————
##############################################################

## new command to get IgG,IgA subtypes!
## first upload primer list
aws s3 cp s3://eric.waltari-bucket/BX_miseq/presto/IgGIgAsubtypes.fasta /mnt/data/presto/IgGIgAsubtypes.fasta

## then command from docker bash:
docker run -it -v /mnt/data/presto:/data:z kleinstein/immcantation:1.10.0 bash

MaskPrimers.py align -s BXtotalHmay5-final_collapse-unique_atleast-5.fastq -p IgGIgAsubtypes.fasta --failed --maxlen 100 --maxerror 0.03 --mode tag --revpr --pf IGGIGA_SUBTYPES

## will also need to update script, re-upload to aegea
aws s3 cp s3://eric.waltari-bucket/BX_miseq/presto/presto-abseq.sh /mnt/data/presto/presto-abseq.sh


## can use the MaskPrimers.py script above also to search for single cell sequences!!
## more to come here...


————
##############################################################
### IGPHYML COMMANDS
##############################################################

https://changeo.readthedocs.io/en/latest/examples/igphyml.html

## this is in development, not in current version of Changeo
docker pull kleinstein/immcantation:1.10.2 
  ## actually not in docker yet! (only in test version of Changeo)

## I have installed igphyml on waltari-immcantation2
 ## first commands use a new Changeo command called BuildTrees.py that reformats the Changeo .tab file...

## on waltari-immcantation2, just created new file called BuildTrees.py - copied actual Python code from https://bitbucket.org/kleinstein/changeo/src/9cb4041a5d5f/bin/?at=default
## then had to copy it into usr/bin (alias /bin) while in immcantation bash
sudo cp data/examples/BuildTrees.py bin/BuildTrees.py
## now can run BuildTrees.py while in Immcantation bash (BUT NOTE THAT igphyml IS ACTUALLY ONLY ON INSTANCE, NOT IN IMMCANTATION BASH)
BuildTrees.py -d example.tab --outname ex --log ex.log --collapse
## THIS DOESN'T WORK - THERE ARE ERRORS IN TRYING TO RUN BuildTrees.py still
  ## THINK ONLY WORKAROUND NOW IS TO INSTALL CHANGEO (AND DEPENDENCIES) ON waltari-immcantation2
    ## alternately, wait until newer docker container version has this updated version of Changeo!!!
    

from changeo.Defaults import default_format, default_v_field, default_j_field, default_junction_field
from changeo.Commandline import CommonHelpFormatter, checkArgs, getCommonArgParser, parseCommonArgs
from changeo.Distance import distance_models, calcDistances, formClusters
from changeo.IO import countDbFile, getDbFields, getFormatOperators, getOutputHandle, \
                       AIRRWriter, ChangeoWriter
from changeo.Multiprocessing import DbResult, feedDbQueue, processDbQueue


from changeo.Defaults import default_format
from changeo.IO import splitFileName, getDbFields, getFormatOperators, getOutputHandle
from changeo.Alignment import getRegions
from changeo.Commandline import CommonHelpFormatter, checkArgs, getCommonArgParser, parseCommonArgs



————
##############################################################
############# SINGLE CELL TRANSCRIPTOME COMMANDS #############
##############################################################

### 5/4 learning from James that a very easy workflow exists:
https://github.com/czbiohub/utilities

## set up utilities-env
conda create --name utilities-env python pip

## go to utilities-env
source activate utilities-env

git clone https://github.com/czbiohub/utilities.git

#run
  ## our run is here 180416_NB501961_0098_AHLNCFBGX5
  ## example aws_star mus 10 YYMMDD_EXP_ID > my_star_jobs.sh
### commands
aws_star homo 24 180416_NB501961_0098_AHLNCFBGX5 > my_star_jobs.sh
cat my_star_jobs.sh
source my_star_jobs.sh

## then aligning
  ## gene_cell_table fastqs/YYMMDD_EXP_ID YYMMDD_EXP_ID.csv --dryrun
gene_cell_table fastqs/180416_NB501961_0098_AHLNCFBGX5 180416_NB501961_0098_AHLNCFBGX5.csv

## PATHWAY ANALYSES
## for pathway analysis: looking at AltAnalyze (stand-alone GUI)
## looks like it can take .tab file of gene counts and do de-novo clustering & pathway analysis...

## running first test on entire .csv file (first saved as tab delimited then changed to .tab)
## this took ~2 hours, made clusters but looks strange (assigning cells to non B-cell functions?)

## trying again with new .tab file taking out unassigned column...
## re-running at 1:30PM

## also works best when comparing two groups (not de-novo clustering)
## assigned 94/96 samples to 'Bcell', last 2 to 'control'

## finding another run with transcriptome data (also Human):
## didn't work because data is archived in Glacier...
## another
gene_cell_table fastqs/180519_NB501961_0110_AHMLH7BGX5 code/180519_NB501961.csv --dryrun

## more AltAnalyze settings:
## after run is finished:
   ### go to Pathway Visualization - file to load is in run directory then /ExpressionOutput/GenMAPP-run_withcontrols.tab.txt
   ## then can choose Human, then giant list of pathways to visualize...
   ## results are in new folder called WikiPathways...
   
   ## also can try Network Visualization (use same output file above as input)
   ## one option to visualize is Bcell-Memory_IgG_IgA-interactions_direct
   ## results are in new folder called networks - NOT VERY MEANINGFUL THOUGH...


